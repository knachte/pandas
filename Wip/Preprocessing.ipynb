{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to preprocess data before doing the train_test_split on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the columns to the correct datatypes \n",
    "When imported data may get assigned datatypes that are not fitting for them.\n",
    "```python\n",
    "df[\"floatValue\"] = df[\"floatAsString\"].astype(float)\n",
    "df['date'] = pd.to_datetime(df['dateAsString'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for NaN's\n",
    "Remove the rows or set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove useless info from useful columns \n",
    "E.g. columns containing temperatures where there is more than what is needed in the data.\n",
    "```python\n",
    "import re\n",
    "my_string = \"temperature: 75.6 F\"\n",
    "pattern = re.compile(\"\\d+\\.\\d+\")\n",
    "out = re.match(pattern, my_string)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with high variance are canidates for log normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the variance of the numerical columns. You can find those with df.var()\n",
    "\n",
    "Apply the log normalization function to the columns with high variance:\n",
    "```python\n",
    "df['numericColumn'] = np.log(df.numericColumn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data with StandardScaler\n",
    "Standard scaler subtracts the mean and divides by the std for each row it is applied to.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#or to scale an entire DataFrame:\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "#to scale a column:\n",
    "    df['column'] = scaler.fit_transform(df[['column']])\n",
    "```\n",
    "Mind the double square brackets in the last example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding binary variables\n",
    "These are columns with two possible choices, e.g. Y/N, Male/Female, ...\n",
    "\n",
    "### Pandas version:\n",
    "```python\n",
    "df[\"encoded_col\"] = df[\"col\"].apply(lambda val: 1 if val == \"y\" else 0)\n",
    "```\n",
    "### LabelEncoder version:\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"encoded_col_le\"] = le.fit_transform(df[\"col\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categories\n",
    "\n",
    "A column that can contain a *limited* number of values. E.g. car brands, colors, ...\n",
    "\n",
    "This format will return just the new columns for this categorical column. It would have to be concatenated and the original column would need to be deleted.\n",
    "```python\n",
    "pd.get_dummies(users[\"fav_color\"])\n",
    "```\n",
    "\n",
    "To do this automatically do the following:\n",
    "```python\n",
    "df = pd.get_dummies(df, columns=[x])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing similar columns by their mean\n",
    "E.g. values from multiple sensors.\n",
    "```python\n",
    "columns=['col1','col2','col3']\n",
    "df[\"mean\"] = df.apply(lambda row: row[columns].mean(), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting parts of a date\n",
    "```python\n",
    "df[\"month\"] = df[\"original_datetime\"].apply(lambda row: row.month)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing text\n",
    "```python\n",
    "tf = term frequency\n",
    "idf = inverse document frequency\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "text_tfidf = tfidf_vec.fit_transform(documents)\n",
    "\n",
    "#get a list of words and their index\n",
    "vocabulary=tfidf_vec.vocabulary_\n",
    "\n",
    "#to get the weights for the words and their index you can use:\n",
    "print(text_tfidf[3].data)\n",
    "print(text_tfidf[3].indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "```\n",
    "**Stratified sampling**:\n",
    "If we know that the distribution of variables in the y column in the dataset is uneven and we wanted to train a model to try to predict y, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA explaining\n",
    "vectorizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
