{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the columns to the correct datatypes \n",
    "When imported data may get assigned datatypes that are not fitting for them.\n",
    "```python\n",
    "df[\"floatValue\"] = df[\"floatAsString\"].astype(float)\n",
    "df['date'] = pd.to_datetime(df['dateAsString'])\n",
    "```\n",
    "To select only columns of a certain type you can use:\n",
    "```python\n",
    "only_ints = df.select_dtypes(include=['int'])\n",
    "```\n",
    "With a for loop you can then perform conversions on these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for NaN's\n",
    "Remove columns if more than 30% of it contains Nan. If less set to the median or mean or zero if this makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove useless info from useful columns \n",
    "E.g. columns containing temperatures where there is more than what is needed in the data.\n",
    "```python\n",
    "import re\n",
    "my_string = \"temperature: 75.6 F\"\n",
    "pattern = re.compile(\"\\d+\\.\\d+\")\n",
    "out = re.match(pattern, my_string)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into categorical and numeric values\n",
    "This can be done by effectively splitting up the data into two DataDrames that will be reassembled later on, or making masks that contain only one of the two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with high variance are canidates for log normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the variance of the numerical columns. You can find those with df.var()\n",
    "\n",
    "Apply the log normalization function to the columns with high variance (> 1000):\n",
    "```python\n",
    "df['numericColumn'] = np.log(df.numericColumn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with low variance can be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns do not contain enough useful data to be of use during the processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "Outliers are values that are far away from the rest of the values and that could cause problems with the model. However, outliers that are linked to the Y axis should be kept, eg an outlier that gives a high sales value should be kept.\n",
    "These outliers should be in the training dataset, not in the test.\n",
    "\n",
    "A good starting point could be to remove everything that is more than 3 standard deviations away from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data with StandardScaler\n",
    "\n",
    "**Apply only during classification, this gives bad results during regression, and is of no use for tree's, forests, etc..**\n",
    "\n",
    "Standard scaler subtracts the mean and divides by the std for each row it is applied to.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#or to scale an entire DataFrame:\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "#to scale a column:\n",
    "    df['column'] = scaler.fit_transform(df[['column']])\n",
    "```\n",
    "Mind the double square brackets in the last example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding binary variables\n",
    "These are columns with two possible choices, e.g. Y/N, Male/Female, ...\n",
    "\n",
    "### Pandas version:\n",
    "```python\n",
    "df[\"encoded_col\"] = df[\"col\"].apply(lambda val: 1 if val == \"y\" else 0)\n",
    "```\n",
    "### LabelEncoder version:\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"encoded_col_le\"] = le.fit_transform(df[\"col\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns that represent grades can be converted to numeric\n",
    "\n",
    "```python\n",
    "dft.ExterQual.replace({\"Ex\":4,\"Gd\":3,\"TA\":2,\"Fa\":1,\"Po\":0}, inplace=True)\n",
    "dft[\"ExterQual\"] = dft[\"ExterQual\"].astype(float)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categories\n",
    "\n",
    "A column that can contain a *limited* number of values. E.g. car brands, colors, ...\n",
    "\n",
    "This format will return just the new columns for this categorical column. It would have to be concatenated and the original column would need to be deleted.\n",
    "```python\n",
    "pd.get_dummies(users[\"fav_color\"])\n",
    "```\n",
    "\n",
    "To do this automatically do the following:\n",
    "```python\n",
    "df = pd.get_dummies(df, columns=[x])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing similar columns by their mean\n",
    "E.g. values from multiple sensors.\n",
    "```python\n",
    "columns=['col1','col2','col3']\n",
    "df[\"mean\"] = df.apply(lambda row: row[columns].mean(), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting parts of a date\n",
    "```python\n",
    "df[\"month\"] = df[\"original_datetime\"].apply(lambda row: row.month)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing text\n",
    "```python\n",
    "tf = term frequency\n",
    "idf = inverse document frequency\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "text_tfidf = tfidf_vec.fit_transform(documents)\n",
    "\n",
    "#get a list of words and their index\n",
    "vocabulary=tfidf_vec.vocabulary_\n",
    "\n",
    "#to get the weights for the words and their index you can use:\n",
    "print(text_tfidf[3].data)\n",
    "print(text_tfidf[3].indices)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "```\n",
    "**Stratified sampling**:\n",
    "If we know that the distribution of variables in the y column in the dataset is uneven and we wanted to train a model to try to predict y, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo:\n",
    "PCA explaining\n",
    "\n",
    "vectorizing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
