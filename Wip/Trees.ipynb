{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification tree makes a prediction on whether given conditions X, y will happen or not. It has a maximum depth to which it can be limited.\n",
    "\n",
    "The class to use is DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train,y_train) \n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate test-set accuracy\n",
    "accuracy_score(y_test, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look up: criterion = gini, entropy, ... (gini is the default if nothing is specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression tree in scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression tree predicts a valye y for given conditions X.\n",
    "\n",
    "The class to use is DecisionTreeRegressor. We can specify a minimum size for the leaves by specifying the min_samples_leaf parameter, which is a value from 0 to 1, representing a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.1, random_state=3)\n",
    "\n",
    "# Fit 'dt' to the training-set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test-set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test-set MSE to \n",
    "mse_dt =  MSE(y_test, y_pred)\n",
    "# Compute test-set RMSE \n",
    "rmse_dt = np.sqrt(mse_dt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation (10-fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation splits the training dataset into 10 parts. Then it trains on 9 of the parts and uses this model on the 10th part to determine the error. The mean of these 10 is the CV error (CVE).\n",
    "\n",
    "If the CVE is bigger than the error on the training set, then there is high variance and the model is overfit. It needs to be made less complex.\n",
    "\n",
    "If the CVE is about the same as the error on the training set, and it is higher than the desired error, then the model has high bias and is underfit. It needs to be made more complex.\n",
    "\n",
    "```python\n",
    "# Evaluate the list of MSE ontained by 10-fold CV \n",
    "# Set n_jobs to -1 in order to exploit all CPU cores in computation\n",
    "MSE_CV = - cross_val_score(dt, X_train, y_train, cv= 10, scoring='neg_mean_squared_error', n_jobs = -1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning uses multiple models like LogisticRegression, DecisionTreeClassifier, and KNeighborsClassifier and then applies a voting system to it, where the most votes win. **This only works for categorized datasets.**\n",
    "\n",
    "```python\n",
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "# Instantiate knn\n",
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "```\n",
    "\n",
    "Place these in a list as tuples:\n",
    "```python\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "```\n",
    "\n",
    "If you want to check the values from these models you can use the following:\n",
    "```python\n",
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:     \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)       \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)    \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
    "```\n",
    "\n",
    "Finally we instantiate a votingclassifier that we pass the models we created earlier and perform a fit on it, after which we can use it to do predictions with a better result than those separately. \n",
    "```python\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging or bootstrap aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. Not all data will be used with this method.\n",
    "\n",
    "The BaggingClassifier constructor takes a parameter n_estimators, which specifies the number of different subsets to sample.\n",
    "\n",
    "```python\n",
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)\n",
    "\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test)) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging works for both classification and regression.\n",
    "\n",
    "For classification it aggregates predictions by majority voting. The class is BaggingClassifier in scikit-learn.\n",
    "\n",
    "For regression it aggregates predictions through averaging. The class is BaggingRegressor in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out Of Bag (OOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since bagging only uses about 63% of the training samples due to it's random nature, around 37% is left unused. These can be used for cross validation. Each sample's model is tested on the unused data for that sample which leads to a set of OOB scores. The mean of these is the final OOB score.\n",
    "\n",
    "The difference is that when the BaggingClassifier is constructed, you need to set oob_score to true.\n",
    "```python\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, oob_score=true, random_state=1)\n",
    "```\n",
    "After having done the .fit and .predict, you can get the OOb score from the BaggingClassifierand compare with the accuracy_score of the testset:\n",
    "```python\n",
    "acc_oob = bc.oob_score_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests work for both classification and regression.\n",
    "\n",
    "For Classification it Aggregates predictions by majority voting. The class is RandomForestClassifier in scikit-learn.\n",
    "For regression it Aggregates predictions through averaging. The class is RandomForestRegressor in scikit-learn.\n",
    "\n",
    "n_estimators is the number of trees in the forest.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = np.sqrt(MSE(y_test, y_pred))\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the importance of the individual features you can use the parameter feature_importances_ of RandomForestRegressor.\n",
    "\n",
    "```python\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_, index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "Classification:\n",
    "\n",
    "Weighted majority voting.\n",
    "In sklearn: AdaBoostClassifier.\n",
    "\n",
    "Regression:\n",
    "\n",
    "Weighted average.\n",
    "In sklearn: AdaBoostRegressor.\n",
    "\n",
    "```python\n",
    "# Instantiate a classification-tree 'dt'\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state=SEED)\n",
    "\n",
    "# Instantiate an AdaBoost classifier 'adab_clf'\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "adb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set probabilities of positive class\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "# Evaluate test-set roc_auc_score\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting\n",
    "Regression: In sklearn: GradientBoostingRegressor.\n",
    "Classification: In sklearn: GradientBoostingClassifier.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=2)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = np.sqrt(MSE(y_test, y_pred))\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do a stochastic gradient boost:\n",
    "Differences: subsample=0.9, max_features=0.75\n",
    "```pyton\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, subsample=0.9, max_features=0.75, n_estimators=200, random_state=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for a Tree\n",
    "\n",
    "model.getparams() returns all the parameters.\n",
    "\n",
    "```python\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define params_dt\n",
    "params_dt = {\"max_depth\":[2,3,4], \"min_samples_leaf\":[0.12, 0.14, 0.16, 0.18]}\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt, param_grid=params_dt, scoring=roc_auc, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametertraining for a RandomForest\n",
    "```python\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_rf = params_rf = { 'n_estimators': [100, 350, 500], 'min_samples_leaf': [2, 10, 30], 'max_features': ['log2', 'auto', 'sqrt']}\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = np.sqrt(MSE(y_test, y_pred))\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
